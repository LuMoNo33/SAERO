---
title: "Neural Networks For Forecasting"
date: 2024-12-15T15:34:30-04:00
categories:
  - Engineering Project
tags:
  - Demand Planning
  - Neural Network
  - Data Science
  - Internship


share: false
---




During my internship at Honeywell Aerospace as a Demand Planner, I was assigned part numbers related to Engines and Power Systems. Each month, we held meetings where everyone presented their forecast accuracy (FA) and discussed their most significant misses. While the forecasting platform offered various methods, the most commonly used was the 12-month moving average. This inspired me to explore the use of trained LSTM neural networks to improve forecast accuracy.


Due to confidentiality agreements, I cannot share the full details of the demand forecasting project I developed using neural networks and machine learning. However, I can provide an overview of the project's foundations and explain how these techniques were utilized to improve forecast accuracy compared to the previously used 12-month moving average method.

All the project was developed using python and mostly using the keras library from TensorFlow, as well as the Scikit-learn. 

```python
from tabnanny import verbose
import numpy as np
import pandas as pd
import math 
import matplotlib.pyplot as plt
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, LSTM, Flatten
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from keras.layers import ConvLSTM2D
from keras.callbacks import EarlyStopping
```
*Most used libraries*

As a foundation for my project, I utilized insights from a series of educational videos on LSTM neural networks by "DigitalSreeni: An introduction to RNN and LSTM". Building on this knowledge, I developed and implemented a genetic algorithm to optimize neuron configurations, significantly improving forecast accuracy. Additionally, I created part clusters to enable parallel forecasting with neural networks, as well as a generalized demand prediction system. 

For a single part, the process is very similar to the one seen in the series. 


```python

early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)

plt.style.use('dark_background')
data = pd.read_csv('/Users/lumono/Python/AirPassengers.csv', usecols=[1])

dataset = data.values
dataset = dataset.astype("float32")

scaler = MinMaxScaler(feature_range=(0,1))
dataset = scaler.fit_transform(dataset)

trainsize = int(len(dataset) * .66)
testsize = len(dataset) - trainsize
train, test = dataset[0:trainsize,:],dataset[trainsize:len(dataset),:]

def sequences(dataset, seq_size = 1):
    x = []
    y = []

    for i in range(len(dataset)-seq_size-1):
        window = dataset[i:(i+seq_size),0]
        x.append(window)
        y.append(dataset[i+seq_size,0])
    
    return np.array(x),np.array(y)

seq_size = 5

trainX,trainY = sequences(train,seq_size)
testX,testY = sequences(test,seq_size)

trainX = np.reshape(trainX,(trainX.shape[0],1,trainX.shape[1]))
testX = np.reshape(testX,(testX.shape[0],1,testX.shape[1]))

model = Sequential()
model.add(LSTM(100, activation="relu", return_sequences=True, input_shape=(None, seq_size)))
model.add(LSTM(50, activation="relu"))
model.add(Dense(32))
model.add(Dense(1))  # Salida directamente

model.compile(loss='mean_squared_error',optimizer='adam')
print(model.summary())

model.fit(trainX, trainY, validation_data=(testX, testY), epochs=100, verbose=2, callbacks=[early_stopping])


trainPredict = model.predict(trainX)
testPredict = model.predict(testX)

trainPredict = scaler.inverse_transform(trainPredict)
trainY = scaler.inverse_transform([trainY])
testPredict = scaler.inverse_transform(testPredict)
testY = scaler.inverse_transform([testY])
    

trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))

print("Train score %.2f RMSE" %(trainScore))

print("Test score %.2f RMSE" %(testScore))
```


This code returns the following graph:

<img src="{{ site.baseurl }}/assets/images/Fattempt.png" alt="Imagen 3" width="500" />


Given the numerous possible combinations of neurons per layer (e.g., 4 LSTM neurons in the first layer, followed by 2 Dense and 2 Dense, or 16 LSTM, 8 Dense, and 4 Dense), a genetic algorithm was implemented to explore the solution space of these configurations. The fitness function was defined as the inverse of the RMSE.

The algorithm utilized a population of 20 individuals, each comprising 2 LSTM layers and 2 Dense layers, with the number of neurons per layer ranging from 4 to 128.

The following are the functions I developed for crossover and mutation within the genetic algorithm:

```python
def crossover(parent1, parent2):
    """
    parent1, parent2: Dos vectores de configuración
    """
    crossover_point = np.random.randint(1, len(parent1))  # Punto de cruce
    child1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))
    child2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))
    return child1, child2
```
```python
def mutate(individual, mutation_rate, bounds):
    """
    individual: Un vector de configuración
    mutation_rate: Probabilidad de mutación
    bounds: Límites de cada gen [(min, max), ...]
    """
    for i in range(len(individual)):
        if np.random.rand() < mutation_rate:
            individual[i] = np.random.randint(bounds[i][0], bounds[i][1])
    return individual
```

By creating a Hall of Fame, the genetic algorithm identified a configuration of neurons per layer that significantly reduced the error. This process is computationally expensive and takes many hours to complete, so it is designed to run only once. As can be seen in the graphs, a proper configuration significantly reduces the RMSE:

<table>
  <tr>
    <td><img src="{{ site.baseurl }}/assets/images/Subopt.png" alt="Imagen 1" width="300" /></td>
    <td><img src="{{ site.baseurl }}/assets/images/OptNN.png" alt="Imagen 3" width="300" /></td>
  </tr>
</table>
*Suboptimal and Optimal configuration*


This method represents the final approach for forecasting a specific part. A comparison was conducted between the LSTM network and the historical forecasting method for the part with the most extensive historical data, revealing that the LSTM method produced a lower RMSE.

However, forecasting individual parts for a portfolio of over 13,000,000 parts would be computationally expensive and impractical. To address this, a cluster prediction method was developed to improve efficiency and reliability.

The k-means method was selected, an unsupervised machine learning algorithm used for clustering data into groups. It iteratively assigns data points to the nearest centroid and recalculates centroids until they stabilize. While efficient and simple, it requires specifying 'k' and can be sensitive to initial centroid placement.
```python
inertia = []

# Probar diferentes valores de k
K_range = range(1, 10)  # Probar de 1 a 10 clusters
for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    inertia.append(kmeans.inertia_)

# Graficar el método del codo
plt.figure(figsize=(8, 5))
plt.plot(K_range, inertia, marker='o')
plt.title('Método del Codo')
plt.xlabel('Número de Clusters (k)')
plt.ylabel('Inercia')
plt.show()
```

To determine the optimal 'k' number of clusters, the elbow method was applied. This involves increasing the number of clusters one by one, measuring the inertia for each, and plotting the results to identify the point where adding more clusters no longer significantly reduces inertia.

<img src="{{ site.baseurl }}/assets/images/KmeansMet.jpeg" alt="Imagen 3" width="500" />

The algorithm correctly identified and grouped the same part that was archived with different part numbers just by looking at the historical demand. Clustering the parts provides additional insights into trends, offering benefits such as enabling sales teams to create packages and capitalize on group sales opportunities. 

All parts were divided into clusters, and an individual neural network was trained for each cluster to predict demand for the next month. Additionally, the model's output was modified to forecast the following five months by adjusting the time window and final dense layer:
```python
model.add(Dense(5))  
```
This approach successfully generated predictions for multiple parts simultaneously by training the neural network with all data from the cluster. Generating predictions for individual parts took less than a second per part.

The project was both challenging and rewarding. During the FA meetings, planners were required to manually categorize the misses into predefined Reason Codes (RC). Implementing a machine learning algorithm to classify these misses into their most likely RC would significantly reduce the time spent on this task, enabling planners to focus on deeper analysis with the rest of the supply chain. Developing this additional algorithm is proposed as a future enhancement to the Neural Network project.

<img src="{{ site.baseurl }}/assets/images/NNPort.jpg" alt="Imagen 3" width="600" />